# .env
# Environment configuration for Outlook AI project

# URL of your remote/local Ollama server
OLLAMA_URL=https://your-openwebui-or-ollama-endpoint/api/chat/completions
API_KEY=your_api_key_here

# Model to use
MODEL_NAME=mistral:instruct

# Batch size for processing emails (future use)
BATCH_SIZE=1

# Enable dry-run mode (no email moving)
DRY_RUN=true

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO
